<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>脚踏车的日志站</title><meta name="author" content="脚踏车没有脚"><meta name="copyright" content="脚踏车没有脚"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="不积跬步，无以至千里">
<meta property="og:type" content="website">
<meta property="og:title" content="脚踏车的日志站">
<meta property="og:url" content="http://yypyyds.github.io/index.html">
<meta property="og:site_name" content="脚踏车的日志站">
<meta property="og:description" content="不积跬步，无以至千里">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yypyyds.github.io/img/touxiang.jpg">
<meta property="article:author" content="脚踏车没有脚">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yypyyds.github.io/img/touxiang.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="http://yypyyds.github.io/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '脚踏车的日志站',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2024-10-30 15:25:58'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = url => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      link.onload = () => resolve()
      link.onerror = () => reject()
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/touxiang.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/banner2.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="脚踏车的日志站"><span class="site-name">脚踏车的日志站</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">脚踏车的日志站</h1></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/09/14/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E7%94%9F%E6%88%90%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" title="扩散模型中的生成控制方法和注意力机制">扩散模型中的生成控制方法和注意力机制</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-09-14T03:08:43.000Z" title="发表于 2024-09-14 11:08:43">2024-09-14</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">扩散模型中的生成控制方法和注意力机制DDPM这是DDPM中的UNet这里的注意力机制是可选的，在DownBlock和UpBlock里面，并且上面每一步都有一个AddTimeEmbedding的操作TimeEmbedding层采用和Transformer一致的三角函数位置编码，将常数转变为向量。Attention层则是沿着channel维度将图片拆分为Token，做完Attention后将输出组装对于是DownBlock还是UpBlock，取决于in_c和out_c的大小
MiddleBlock是残差，注意力，残差的形式，和上面类似
这个attention还是分论文，有的有有的没有
LDMLDM相比DM，就是在图像压缩域做扩散，这是有理论支持的随着比特数的增加，失真程度先降很快，然后再平缓对应的意思是，在低比特数的小图上增加比特数，语义信息加的更多但是在分辨率变得越来越高时，加的信息主要是感知信息而扩散模型学到的主要是结构，忽略细节，所以让他建模语义信息更好（生成小图）
在LDM中的条件导入，是通过cross-attention导入的这个条件编码器是一个特定于数据域的编码器，每种模态都不 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/07/08/%E9%9F%B3%E4%B9%90%E7%94%9F%E6%88%90%E9%9A%90%E5%86%99/" title="音乐生成隐写">音乐生成隐写</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-07-08T08:20:58.000Z" title="发表于 2024-07-08 16:20:58">2024-07-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="content">音乐生成隐写先列一下要做的几件事找近三年文生音乐的论文找音频隐写，视频隐写，图像隐写的论文
音乐生成应该多找点，然后筛48k的暂未录用：High Fidelity Text-Guided Music Generation and Editing via Single-Stage Flow Matchingtext controlled, 48k stereo，支持文本细粒度控制，支持长时间的风格转换，没开源
Accompanied Singing Voice Synthesis with Fully Text-controlled Melodytext, MIDI controlled, 伴奏合成, 24k mono, 合成人声和伴奏，听着对不太上，没开源
ICML2024: MusicFlow: Cascaded Flow Matching for Text Guided Music Generation
MusicGen: Simple and Controllable Music Generation  codeMusicLDM: Enhancing Novelty in Tex ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/05/15/%E5%AF%B9LDM%E4%BB%A3%E7%A0%81%E7%9A%84%E5%AD%A6%E4%B9%A0/" title="对LDM代码的学习">对LDM代码的学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-05-15T07:34:44.000Z" title="发表于 2024-05-15 15:34:44">2024-05-15</time></span></div><div class="content">对LDM代码的学习看了下ControlNet，感觉要完全掌握这个技术，需要对扩散模型的代码十分熟悉，所以打算再集中研究一下Make-an-Audio的训练过程，然后看看如何在这个的基础上去进行下一步工作。
Make an audio代码开源代码中把VAE也训练了，就调试一下Diffusion的训练过程模型的生成训练目标是ldm.models.diffusion.ddpm_audio.LatentDiffusion_audio该文件下还有其他两个类 LatentFinetuneDiffusion, LatentInpaintDiffusion注释里写道，前者是Basis for different finetunes, such as inpainting or depth2image先不管，反正是重建的做Inpainting的工作，先把正经生成搞懂
这篇文章真的是神中神 链接
LatentDiffusion_audio类这里的on_train_batch_start用到了一个std-rescaling看的卵痛于是回来复习Diffusion的数学知识了
准确来说，加噪声并不是给上一时刻的 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/04/08/%E7%94%9F%E6%88%90%E7%9B%B8%E5%85%B3/" title="生成相关">生成相关</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-04-08T09:00:48.000Z" title="发表于 2024-04-08 17:00:48">2024-04-08</time></span></div><div class="content">生成相关AudiogenICLR 2023Meta AI包括两个主要的阶段第一阶段将原始音频编码成离散的token序列，通过一个压缩模型进行该模型以端到端的方式进行训练，使用压缩表示重建输入音频，并以一组鉴别器的形式添加感知损失。第二阶段使用一个自回归的Transformer-decoder language-model，在文本条件的基础上重建音频序列
主要贡献：

sota方法
提高TTA生成性能的两个方法：classifier free guidance，动态文本和音频混合来提高组合性
可以做条件和非条件的音频延续
探索了音频保真度和采样时间之间的关系MethodAudio representation一个时长为d的音频信号可以表示为一个序列 $x\in[-1,1]^{C_a \times T}$ ，$C_a$ 是通道数，$T=d\cdot f_{sr}$ 是采样点数，至于为什么是 $[-1,1]$ ，是因为py库读取wav文件会自动归一化Audio representation model 包含三个部分


encoder network E：将音频片段作为输入，输出一个late ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/03/25/PyTorch%20Lighting%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/" title="PyTorch Lighting框架学习">PyTorch Lighting框架学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2024-03-25T07:29:07.000Z" title="发表于 2024-03-25 15:29:07">2024-03-25</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/">技术问题记录</a></span></div><div class="content">PyTorch Lighting框架学习最近在搞一个挑战赛，但是感觉自己写的代码好难看，很混乱，而且大部分还是复用别人的东西，所以打算系统学习一下这个简洁的框架。
parser先把这个学了，然后去看那个参数转实例的参考链接
dataset看一个知乎的帖子，讲到的一种项目组织方法：1234567891011121314root-    |-data        |-__init__.py        |-data_interface.py        |-xxxdataset1.py        |-xxxdataset2.py        |-...    |-model        |-__init__.py        |-model_interface.py        |-xxxmodel1.py        |-xxxmodel2.py        |-...    |-main.py我在root下还加了个config.py，上面这种方法，在data_interface和model_interface中，分别写数据集和模型的wrapper，然后在main中 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/30/StegaDDPM/" title="StegaDDPM">StegaDDPM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-11-30T08:38:03.000Z" title="发表于 2023-11-30 16:38:03">2023-11-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="content">StegaDDPM
In addition, it can securely conceal and accurately extract secret messages up to 9 bits per pixel.

汗流浃背了，一个像素的信息量也没有9比特吧
Introduction隐写有基于嵌入的隐写和无需嵌入的隐写
Proposed Approach
基于DDPM的隐写网络又讲了一遍DiffusionStegaDDPM分析了DDPM的逆生成过程来实现生成式图像隐写，并推导出适合于隐写的两个属性。详情如下

消噪扩散概率模型定义了扩散步骤的马尔可夫链。
Z的分量服从高斯分布，其维数与生成的图像的维数相等。算法：和传统DDPM模型生成图像的不同：初始采样噪声（即 $t=T$ 时）使用约定的 $Seed_1$ 生成，中间的去噪过程使用 $Seed_2$ 作为Diffusion去噪条件（类比条件诱导生成中的条件特征向量？），在最后一步使用一个残差 $R_1$ 作为嵌入信息，得到隐写图片 $X_0^S$

信息隐藏和提取隐藏过程秘密信息 $m$ ，长 $L$， 使用 $K$ 先加密得到 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/28/AudioLDM2/" title="AudioLDM2">AudioLDM2</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-11-28T02:33:00.000Z" title="发表于 2023-11-28 10:33:00">2023-11-28</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="content">AudioLDM2作者：Haohe Liu, Qiao Tian, Yi Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Yuping Wang, Wenwu Wang, Yuxuan Wang, Mark D. Plumbley
Introduction做Audio generation的大一统工作（有空可以看看这里提到的几篇）

Recent advancements in addressing problems from a unified perspective have yielded substantial progress [16]– [19]. This trend highlights the potential of constructing a unified audio generation framework.

引入了 language of audio(LOA)，作为音频片段的特征表示，这个片段需要能够表示细粒度和粗粒度的音频信息，考虑到这些需求，我们建议使用 audio masked autoencoder(Audi ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/20/CLAP/" title="CLAP">CLAP</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-11-20T08:25:06.000Z" title="发表于 2023-11-20 16:25:06">2023-11-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="content">CLAP : LEARNING AUDIO CONCEPTS FROM NATURAL LANGUAGE SUPERVISION作者：Benjamin Elizalde, Soham Deshmukh, Mahmoud Al Ismail, Huaming Wang机构：微软发表情况：未发表
Introduction注意到在这之前，也有人用类似的方法训练，Wav2clip和Audioclip从CLIP中提取，并且使用AS中的音频和类别标签训练而不是自然语言（应该就是这里的区别）CLAP使用和CLIP一样的方法，两个Encoder，通过对比学习将音频和文本描述投射到一个联合的多模态空间
方法
和图中描述的一样首先需要选定一个大小为 $N$ 的 batch，就是图中做矩阵乘法的两个向量组的大小。图里省略了两个线性投影层audio是以梅尔谱图的形式作为输入的

\hat X_a = f_a(X_a);\;\hat X_t = f_t(X_t)其中 $\hat X_a \in \mathbb R ^{N\times V},\hat X_t \in \mathbb R ^{N\times U}$ ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/13/AudioLDM/" title="AudioLDM">AudioLDM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-11-13T02:45:19.000Z" title="发表于 2023-11-13 10:45:19">2023-11-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="content">AudioLDM作者：Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, Mark D. Plumley机构：CVSSP, University of Surrey, Guildford, UK；Department of EEE, Imperial College London, London, UK发表情况： ICML 2023
学习过程参考的相关文章Diffusion Model
Introduction贡献：

第一次将连续的隐扩散模型（LDM）应用于TTA生成，且取得了SOTA效果
使用了CLAP嵌入使TTA生成的训练不用依赖音频文本对
实验证明了在LDM训练中只使用音频数据可以得到高质量和高计算效率的TTA系统
展示了提出的TTA系统能够在未经过微调的情况下进行文本引导的音频风格操作，比如音频风格迁移，高分辨率生成，音频修复。


Text-Conditional Audio GenerationContrastive Language-Audio Pretrain ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/11/07/VQ-VAE%E7%9B%B8%E5%85%B3/" title="VQ-VAE相关">VQ-VAE相关</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2023-11-07T08:57:48.000Z" title="发表于 2023-11-07 16:57:48">2023-11-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a></span></div><div class="content">VQ-VAE相关相关文章原理解读：

https://zhuanlan.zhihu.com/p/657857297
https://zhuanlan.zhihu.com/p/633744455
https://www.spaces.ac.cn/archives/6760
https://zhuanlan.zhihu.com/p/260627899
https://zhuanlan.zhihu.com/p/429686815

实现：

https://zhuanlan.zhihu.com/p/640000410

Auto Encoder自动编码器，由一对编码器和解码器组成，编码器从原始数据中抽取出隐变量特征，解码器使用这个隐变量去还原原始数据
自动编码器是一种数据的压缩算法，其中数据的压缩和解压缩函数是数据相关的、有损的、从样本中自动学习的这个框架在训练完成之后，编解码过程是没有随机性的，常用于特征提取
对于AE，如果我们想随机生成一个隐变量，送入Decoder中得到一个生成的数据，这样做往往是行不通的（为什么
这里引入一个向量空间的概念，隐变量实际上就是一个多维向量，每一个输入的数 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/touxiang.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">脚踏车没有脚</div><div class="author-info__description">不积跬步，无以至千里</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/yypyyds"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">这是一个努力学习的笨蛋的博客</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/14/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E7%94%9F%E6%88%90%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95%E5%92%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" title="扩散模型中的生成控制方法和注意力机制">扩散模型中的生成控制方法和注意力机制</a><time datetime="2024-09-14T03:08:43.000Z" title="发表于 2024-09-14 11:08:43">2024-09-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/08/%E9%9F%B3%E4%B9%90%E7%94%9F%E6%88%90%E9%9A%90%E5%86%99/" title="音乐生成隐写">音乐生成隐写</a><time datetime="2024-07-08T08:20:58.000Z" title="发表于 2024-07-08 16:20:58">2024-07-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/15/%E5%AF%B9LDM%E4%BB%A3%E7%A0%81%E7%9A%84%E5%AD%A6%E4%B9%A0/" title="对LDM代码的学习">对LDM代码的学习</a><time datetime="2024-05-15T07:34:44.000Z" title="发表于 2024-05-15 15:34:44">2024-05-15</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/04/08/%E7%94%9F%E6%88%90%E7%9B%B8%E5%85%B3/" title="生成相关">生成相关</a><time datetime="2024-04-08T09:00:48.000Z" title="发表于 2024-04-08 17:00:48">2024-04-08</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/03/25/PyTorch%20Lighting%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/" title="PyTorch Lighting框架学习">PyTorch Lighting框架学习</a><time datetime="2024-03-25T07:29:07.000Z" title="发表于 2024-03-25 15:29:07">2024-03-25</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%A3%B0%E5%AD%A6%E7%9B%B8%E5%85%B3/"><span class="card-category-list-name">声学相关</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"><span class="card-category-list-name">技术问题记录</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9F%A5%E9%98%85%E7%94%A8/"><span class="card-category-list-name">查阅用</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">论文笔记</span><span class="card-category-list-count">7</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Attention/" style="font-size: 1.1em; color: #999">Attention</a> <a href="/tags/CLAP/" style="font-size: 1.1em; color: #999">CLAP</a> <a href="/tags/Diffusion/" style="font-size: 1.3em; color: #99a1ac">Diffusion</a> <a href="/tags/SED/" style="font-size: 1.1em; color: #999">SED</a> <a href="/tags/VAE/" style="font-size: 1.1em; color: #999">VAE</a> <a href="/tags/pytorch-lighting/" style="font-size: 1.1em; color: #999">pytorch_lighting</a> <a href="/tags/%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/" style="font-size: 1.1em; color: #999">信号处理</a> <a href="/tags/%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/" style="font-size: 1.1em; color: #999">傅里叶变换</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 1.1em; color: #999">机器学习</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.3em; color: #99a1ac">深度学习</a> <a href="/tags/%E7%94%9F%E6%88%90/" style="font-size: 1.1em; color: #999">生成</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 1.5em; color: #99a9bf">论文</a> <a href="/tags/%E9%9A%90%E5%86%99/" style="font-size: 1.3em; color: #99a1ac">隐写</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">九月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">十一月 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">十月 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">八月 2023</span><span class="card-archive-list-count">2</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">13</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-10-30T07:25:58.867Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By 脚踏车没有脚</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>